## ğŸ“š ROADMAP: PrÃ³ximas Etapas - IntegraÃ§Ã£o PubMed

*Guia passo a passo para implementar a coleta de dados do PubMed*

---

## ğŸ¯ OBJETIVO DA PRÃ“XIMA ETAPA

Implementar o mÃ³dulo `processing/collectors/pubmed.py` para:
- âœ… Buscar artigos no PubMed usando Entrez (BIoPython)
- âœ… Validar afiliaÃ§Ãµes com dados da tabela `affiliation_variations`
- âœ… Salvar artigos validados no banco de dados
- âœ… Registrar erros de validaÃ§Ã£o

---

## ğŸ“‹ DEPENDÃŠNCIAS NECESSÃRIAS

### JÃ¡ Instaladas
```
âœ… PySide6        (Interface)
âœ… SQLite3        (Banco de dados - padrÃ£o do Python)
```

### Precisa Instalar
```bash
pip install biopython
pip install openpyxl  # Para exportar depois
```

---

## ğŸ”§ ESTRUTURA DO `pubmed.py`

```python
# processing/collectors/pubmed.py

from Bio import Entrez
from database import DatabaseManager, Article, AffiliationVariation, ErrorLog
from datetime import datetime

class PubMedCollector:
    """Coleta artigos do PubMed"""
    
    def __init__(self):
        self.db = DatabaseManager()
        Entrez.email = "seu_email@example.com"  # ObrigatÃ³rio
    
    def search_articles(self, search_term: str, date_start: str, date_end: str) -> list:
        """Busca artigos no PubMed"""
        # Implementar
        pass
    
    def fetch_article_details(self, pmid: str) -> dict:
        """Busca detalhes de um artigo especÃ­fico"""
        # Implementar
        pass
    
    def validate_affiliation(self, article: dict) -> bool:
        """Verifica se o artigo tem afiliaÃ§Ã£o com HC-UFPE"""
        # Implementar
        pass
    
    def save_article(self, article_data: dict, validated: bool):
        """Salva artigo no banco de dados"""
        # Implementar
        pass
    
    def collect_and_save(self, search_term: str, date_start: str, date_end: str):
        """Pipeline completo: buscar â†’ validar â†’ salvar"""
        # Implementar
        pass
```

---

## ğŸ“ PASSO A PASSO DE IMPLEMENTAÃ‡ÃƒO

### Passo 1: Instalar BIoPython
```bash
pip install biopython
```

### Passo 2: Entender a API do Entrez
```python
from Bio import Entrez

Entrez.email = "tiago.renan@example.com"  # IMPORTANTE!

# Buscar
handle = Entrez.esearch(db="pubmed", term="Hospital das ClÃ­nicas", retmax=100)
records = Entrez.read(handle)

# Obter IDs
pmids = records["IdList"]

# Buscar detalhes
handle = Entrez.efetch(db="pubmed", id=",".join(pmids), rettype="xml")
records = Entrez.read(handle)
```

### Passo 3: Extrair Dados do XML
```python
for record in records['PubmedArticle']:
    # Extrair campos
    title = record['MedlineCitation']['Article']['ArticleTitle']
    authors = record['MedlineCitation']['Article'].get('AuthorList', [])
    abstract = record['MedlineCitation']['Article'].get('Abstract', {}).get('AbstractText', [''])[0]
    doi = # ... extrair do artigo
    pubdate = # ... extrair data
```

### Passo 4: Validar AfiliaÃ§Ã£o
```python
def validate_affiliation(article_text: str) -> bool:
    """Verifica se o texto menciona HC-UFPE ou variaÃ§Ãµes"""
    
    # Obter todas as variaÃ§Ãµes cadastradas
    with DatabaseManager() as db:
        variations = db.read_affiliation_variations_by_institution("HC-UFPE")
    
    # Verificar se alguma variaÃ§Ã£o estÃ¡ no artigo
    for var in variations:
        if var.original_text.lower() in article_text.lower():
            return True
    
    return False
```

### Passo 5: Salvar no Banco
```python
def save_article(article_data: dict, validated: bool):
    """Salva artigo no banco de dados"""
    
    with DatabaseManager() as db:
        article = Article(
            title=article_data['title'],
            authors=article_data['authors'],
            doi=article_data['doi'],
            platform="PubMed",
            publication_date=article_data['pubdate'],
            abstract=article_data['abstract'],
            url=article_data['url'],
            status="VALIDADO" if validated else "NOVO"
        )
        
        article_id = db.create_article(article)
        
        # Se nÃ£o passou na validaÃ§Ã£o, registrar erro
        if not validated:
            error = ErrorLog(
                error_type="RejeiÃ§Ã£o de ConteÃºdo",
                article_title=article_data['title'],
                article_doi=article_data['doi'],
                platform="PubMed",
                error_reason="Nenhuma afiliaÃ§Ã£o com HC-UFPE encontrada"
            )
            db.create_error_log(error)
```

---

## ğŸ§ª PSEUDOCÃ“DIGO COMPLETO

```python
# processing/collectors/pubmed.py

class PubMedCollector:
    
    def __init__(self):
        self.db = DatabaseManager()
        Entrez.email = "tiago@example.com"
    
    def collect_and_save(self, search_term, date_start, date_end):
        """Pipeline completo"""
        
        print(f"ğŸ” Buscando '{search_term}' no PubMed...")
        
        # 1. Buscar no PubMed
        pmids = self.search_articles(search_term, date_start, date_end)
        print(f"   Encontrados {len(pmids)} artigos")
        
        # 2. Registrar busca no histÃ³rico
        with self.db as db:
            from database import SearchHistory
            search = SearchHistory(
                search_term=search_term,
                platforms="PubMed",
                date_start=date_start,
                date_end=date_end,
                results_count=len(pmids)
            )
            db.create_search_history(search)
        
        # 3. Para cada artigo
        validated_count = 0
        rejected_count = 0
        
        for pmid in pmids:
            try:
                # Obter detalhes
                article_data = self.fetch_article_details(pmid)
                
                # Validar afiliaÃ§Ã£o
                validated = self.validate_affiliation(article_data)
                
                # Salvar no banco
                self.save_article(article_data, validated)
                
                if validated:
                    validated_count += 1
                else:
                    rejected_count += 1
                    
            except Exception as e:
                print(f"   âœ— Erro processando PMID {pmid}: {e}")
                rejected_count += 1
        
        print(f"   âœ“ {validated_count} artigos VALIDADOS")
        print(f"   âœ— {rejected_count} artigos REJEITADOS")
```

---

## ğŸ”— COMO INTEGRAR COM A INTERFACE

No `main_window.py`, quando o usuÃ¡rio clica em "PESQUISAR":

```python
# Interface/main_window.py

def iniciar_busca(self):
    search_term = self.search_term_input.text()
    date_start = self.date_start_input.date().toString("yyyy-MM-dd")
    date_end = self.date_end_input.date().toString("yyyy-MM-dd")
    platforms = self.default_search_config['platforms']
    
    # Importar collector
    from processing.collectors.pubmed import PubMedCollector
    
    collector = PubMedCollector()
    
    # Se PubMed estÃ¡ selecionado
    if "PubMed" in platforms:
        collector.collect_and_save(search_term, date_start, date_end)
    
    # Depois mostrar resultados
    with DatabaseManager() as db:
        articles = db.read_articles_by_status("VALIDADO")
    
    self.open_results_window(articles)
```

---

## ğŸ“Š FLUXOGRAMA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UsuÃ¡rio clica "PESQUISAR" na GUI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PubMedCollector.collect_and_save()    â”‚
â”‚  search_term: "Hospital das ClÃ­nicas"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Buscar no PubMed (Entrez.esearch) â”‚
â”‚     â†’ Retorna 500 PMIDs                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Registrar no HistÃ³rico              â”‚
â”‚     SearchHistory table                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Para cada PMID:                    â”‚
â”‚     - Obter detalhes (Entrez.efetch)  â”‚
â”‚     - Validar afiliaÃ§Ã£o                â”‚
â”‚     - Salvar no BD                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
       â–¼                â–¼
    âœ“ VALIDADO     âœ— REJEITADO
     (Salvar)      (Log erro)
       â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Retornar artigos para GUI           â”‚
â”‚     db.read_articles_by_status()       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mostrar resultados na tela             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… CHECKLIST DE IMPLEMENTAÃ‡ÃƒO

- [ ] Instalar BIoPython: `pip install biopython`
- [ ] Criar `processing/collectors/pubmed.py`
- [ ] Implementar `search_articles()`
- [ ] Implementar `fetch_article_details()`
- [ ] Implementar `validate_affiliation()`
- [ ] Implementar `save_article()`
- [ ] Implementar `collect_and_save()`
- [ ] Testar com dados reais do PubMed
- [ ] Integrar com interface GUI
- [ ] Adicionar tratamento de erros
- [ ] Documentar a classe

---

## ğŸš€ TEMPO ESTIMADO

- Estudo da API Entrez: 30 min
- ImplementaÃ§Ã£o bÃ¡sica: 1-2 horas
- Testes: 30 min - 1 hora
- IntegraÃ§Ã£o com GUI: 30 min
- **Total: 2-4 horas**

---

## ğŸ“š RECURSOS ÃšTEIS

- [BIoPython Documentation](https://biopython.org/)
- [NCBI Entrez Tutorial](https://www.ncbi.nlm.nih.gov/books/NBK25499/)
- [PubMed XML Structure](https://www.nlm.nih.gov/bsd/mms/medlinexml_structure.html)
- DocumentaÃ§Ã£o completa do CRUD: `DATABASE_CRUD_GUIDE.md`

---

## ğŸ’¡ DICAS

1. **Teste localmente primeiro** com um Ãºnico termo
2. **Use rate limiting** (NCBI pede esperar entre requisiÃ§Ãµes)
3. **Trate timeouts** (conexÃ£o pode falhar)
4. **Cache resultados** se possÃ­vel (economiza requisiÃ§Ãµes)
5. **Registre erros** em ErrorLog para debug

---

## ğŸ“ EXEMPLO FINAL

```python
if __name__ == "__main__":
    collector = PubMedCollector()
    
    # Exemplo de busca
    collector.collect_and_save(
        search_term="Hospital das ClÃ­nicas UFPE",
        date_start="2023-01-01",
        date_end="2024-12-31"
    )
    
    # Verificar resultados
    with DatabaseManager() as db:
        stats = db.get_stats()
        print(f"Artigos salvos: {stats['articles_total']}")
```

---

**Pronto para comeÃ§ar? Boa sorte! ğŸš€**
